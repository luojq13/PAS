/**
 * Created by root on 4/11/17.
 */
/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package SparkStreaming;

import java.io.File;
import java.io.FileWriter;
import java.util.*;
import java.util.regex.Pattern;
import java.text.DateFormat;
import java.text.SimpleDateFormat;
import java.time.LocalDateTime;

import edu.thss.platform.pas.userfunc.UserFunction;
import kafka.serializer.StringDecoder;
import org.apache.spark.streaming.api.java.*;
import org.apache.spark.streaming.kafka.KafkaUtils;
import scala.Tuple2;
import com.alibaba.fastjson.*;
import com.datastax.driver.core.*;

import com.sagittarius.bean.result.FloatPoint;
import com.sagittarius.read.Reader;
import com.sagittarius.util.TimeUtil;
import com.sagittarius.bean.result.*;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.api.java.StorageLevels;
import org.apache.spark.streaming.Durations;

/**
 * Counts words in UTF8 encoded, '\n' delimited text received from the network every second.
 *
 * Usage: SparkStreaming.RunTask <hostname> <port>
 * <hostname> and <port> describe the TCP server that Spark Streaming would connect to receive data.
 *
 * To run this on your local machine, you need to first run a Netcat server
 *    `$ nc -lk 9999`
 * and then run the example
 *    `$ bin/run-example org.apache.spark.examples.streaming.SparkStreaming.RunTask localhost 9999`
 */
public final class RunTask {
    private static final Pattern SPACE = Pattern.compile(" ");

    public static void main(String[] args) throws Exception {
        if (args.length < 2) {
            System.err.println("Usage: SparkStreaming.RunTask <hostname> <port>");
            System.exit(1);
        }

        //StreamingExamples.setStreamingLogLevels();

        // Create the context with a 1 second batch size
        String[] jars = new String[]{"file:///home/seasons/Desktop/git/New1/PAS/classes/artifacts/pas_jar2/pas.jar"};
        //SparkConf sparkConf = new SparkConf().setAppName("SparkStreaming.RunTask").setMaster("spark://sparkMaster:7077").setJars(jars);
        SparkConf sparkConf = new SparkConf().setAppName("SparkStreaming.RunTask").setMaster("local[*]").setJars(jars);
        JavaStreamingContext jssc = new JavaStreamingContext(sparkConf, Durations.seconds(1));

        //String brokers = "192.168.15.124:9092";
        //String topics = "test_pas";
        /*String brokers = "192.168.15.219:9092";
        String topics = "PAS";

        Set<String> topicsSet = new HashSet<>(Arrays.asList(topics.split(",")));
        Map<String, String> kafkaParams = new HashMap<>();
        kafkaParams.put("metadata.broker.list", brokers);

        // Create direct kafka stream with brokers and topics
        JavaPairInputDStream<String, String> messages = KafkaUtils.createDirectStream(
                jssc,
                String.class,
                String.class,
                StringDecoder.class,
                StringDecoder.class,
                kafkaParams,
                topicsSet
        );

        JavaDStream<String> lines = messages.map(new Function<Tuple2<String, String>, String>() {
            @Override
            public String call(Tuple2<String, String> tuple2) {

                System.out.println("queries: " + tuple2._2());
                return tuple2._2();
            }
        });*/

        // Create a JavaReceiverInputDStream on target ip:port and count the
        // words in input stream of \n delimited text (eg. generated by 'nc')
        // Note that no duplication in storage level only for running locally.
        // Replication necessary in distributed scenario for fault tolerance.
        JavaReceiverInputDStream<String> lines = jssc.socketTextStream(
                args[0], Integer.parseInt(args[1]), StorageLevels.MEMORY_AND_DISK_SER);
        System.out.println("count = " + lines.count());
        JavaDStream<UserQuery> queries = lines.map(new Function<String, UserQuery>() {
            @Override
            public UserQuery call(String x) throws Exception{
                System.out.println("queries: " + x);
                return JSON.parseObject(x, UserQuery.class);
            }
        });
        JavaDStream<Pair<String, UserQuery>> jobs = queries.flatMap(
                new FlatMapFunction<UserQuery, Pair<String, UserQuery>>() {
                    @Override public Iterator<Pair<String, UserQuery>> call(UserQuery x) {

                        if (x.get_group().equals("DEVICE")){
                            //System.out.println("jobs(DEVICE): " + JSON.toJSON(x));
                            List<Pair<String, UserQuery>> a = new ArrayList<>();
                            List<String> devs = x.get_devList();
                            List<String> _devs = new ArrayList<String>();
                            for (String dev: devs) {
                                _devs.clear();
                                _devs.add(dev);
                                x.set_devList(_devs);
                                a.add(new Pair<>(dev, new UserQuery(x)));
                            }
                            return a.iterator();
                        }
                        else if (x.get_group().equals("DAY") || x.get_group().equals("DEVICE&DAY")){
                            //System.out.println("jobs(DAY): " + JSON.toJSON(x));
                            SimpleDateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
                            SimpleDateFormat dayFormat = new SimpleDateFormat("yyyy-MM-dd");
                            List<Pair<String, UserQuery>> a = new ArrayList<>();
                            List<UserQuery> xs = new ArrayList<>();
                            if (x.get_group().equals("DAY")){
                                xs.add(x);
                            } else {
                                List<String> devs = x.get_devList();
                                List<String> _devs = new ArrayList<String>();
                                for (String dev: devs) {
                                    _devs.clear();
                                    _devs.add(dev);
                                    x.set_devList(_devs);
                                    xs.add(new UserQuery(x));
                                }
                            }
                            try {
                                for (UserQuery xi: xs) {
                                    long start0 = TimeUtil.string2Date(xi.get_extractStartTime(), dateFormat);
                                    long end0 = TimeUtil.string2Date(xi.get_extractEndTime(), dateFormat);
                                    //System.out.println("time: " + start0 + " ~ " + end0);
                                    long daytime = 86400000;
                                    long offset = daytime / 3 * 2;//GMT+8
                                    start0 -= offset;
                                    end0 -= offset;
                                    long start = start0 / daytime * daytime + daytime;
                                    long end = end0 / daytime * daytime;
                                    //start day
                                    if (start0 < start && start <= end0) {
                                        xi.set_extractStartTime(dateFormat.format(start0 + offset));
                                        xi.set_extractEndTime(dateFormat.format(start - 1 + offset));
                                        a.add(new Pair<>(dayFormat.format(start0 + offset), new UserQuery(xi)));
                                    }
                                    //each day
                                    while (start < end) {
                                        xi.set_extractStartTime(dateFormat.format(start + offset));
                                        xi.set_extractEndTime(dateFormat.format(start + daytime - 1 + offset));
                                        a.add(new Pair<>(dayFormat.format(start + offset), new UserQuery(xi)));
                                        start += daytime;
                                    }
                                    //end day
                                    if (start0 <= end && end < end0) {
                                        xi.set_extractStartTime(dateFormat.format(end + offset));
                                        xi.set_extractEndTime(dateFormat.format(end0 + offset));
                                        a.add(new Pair<>(dayFormat.format(end + offset), new UserQuery(xi)));
                                    }
                                    //special case: timeslice in one day
                                    if (start > end) {
                                        xi.set_extractStartTime(dateFormat.format(start0 + offset));
                                        xi.set_extractEndTime(dateFormat.format(end0 + offset));
                                        a.add(new Pair<>(dayFormat.format(start0 + offset), new UserQuery(xi)));
                                    }
                                }
                            } catch(Exception e){
                                e.printStackTrace();
                            }

                            return a.iterator();
                        }
                        //System.out.println("OMG!!!!" + x.get_group());
                        return null;

                        //return Arrays.asList(x.split(" ")).iterator();
                    }
                });
        JavaPairDStream<String, List<Map<String,Object>>> rets = jobs.mapToPair(
                new PairFunction<Pair<String, UserQuery>, String, List<Map<String,Object>>>(){
                    @Override public Tuple2<String, List<Map<String,Object>>> call(Pair<String, UserQuery> s) throws Exception{

                        //System.out.println("\n#job: " + s.getFirst());
                        //System.out.println(JSON.toJSON(s));

                        UserQuery q = s.getSecond();
                        String group = q.get_group();
                        String groupId = s.getFirst();
                        //System.out.println("group: " + group + ", " + groupId);

                        //loadJar
                        String classPath = q.get_className();
                        String jarPath = "file:///home/seasons/Desktop/MRO/" + q.get_jarName();
                        System.out.println("jarp: " + jarPath);
                        //UserFunction impl = (UserFunction) new TempFaultDist();
                        UserFunction impl = LoadJar.loadJar1(classPath, jarPath);

                        //getInput
                        Reader reader = KMXUtil.getReader();
                        ArrayList<String> hosts = new ArrayList<>();
                        hosts.addAll(q.get_devList());

                        ArrayList<String> floatMetrics = new ArrayList<>();
                        floatMetrics.addAll(q.get_floatTParaList());

                        ArrayList<String> stringMetrics = new ArrayList<>();
                        stringMetrics.addAll(q.get_stringTParaList());

                        ArrayList<String> doubleMetrics = new ArrayList<>();
                        doubleMetrics.addAll(q.get_doubleTParaList());

                        ArrayList<String> intMetrics = new ArrayList<>();
                        intMetrics.addAll(q.get_intTParaList());

                        ArrayList<String> longMetrics = new ArrayList<>();
                        longMetrics.addAll(q.get_longTParaList());

                        ArrayList<String> booleanMetrics = new ArrayList<>();
                        booleanMetrics.addAll(q.get_booleanTParaList());

                        ArrayList<String> geoMetrics = new ArrayList<>();
                        geoMetrics.addAll(q.get_geoTParaList());

                        //result
                        List<Map<String,Object>> a = new ArrayList<Map<String,Object>>();

                        try {
                            long start = TimeUtil.string2Date(q.get_extractStartTime(), new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"));
                            long end = TimeUtil.string2Date(q.get_extractEndTime(), new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"));

                            //System.out.println("this time: " + start + " ~ " + end);

                            Map<String, Map<String, List<FloatPoint>>> input1 = reader.getFloatRange(hosts, floatMetrics, start, end);
                            Map<String, Map<String, List<DoublePoint>>> input2 = reader.getDoubleRange(hosts, doubleMetrics, start, end);
                            Map<String, Map<String, List<StringPoint>>> input3 = reader.getStringRange(hosts, stringMetrics, start, end);
                            Map<String, Map<String, List<IntPoint>>> input4 = reader.getIntRange(hosts, intMetrics, start, end);
                            Map<String, Map<String, List<LongPoint>>> input5 = reader.getLongRange(hosts, longMetrics, start, end);
                            Map<String, Map<String, List<BooleanPoint>>> input6 = reader.getBooleanRange(hosts, booleanMetrics, start, end);
                            Map<String, Map<String, List<GeoPoint>>> input7 = reader.getGeoRange(hosts, geoMetrics, start, end);

                            //run
                            Map<String, Object> ans = new HashMap<>(impl.runOne(hosts, input1, input2, input3, input4, input5, input6, input7, start, end));
                            //getOutput
                            if (group.equals("DEVICE")) {
                                ans.put("group", "deviceId");
                                ans.put("deviceId", groupId);
                            } else if (group.equals("DAY")){
                                ans.put("group", "date");
                                ans.put("date", groupId);
                            } else if (group.equals("DEVICE&DAY")) {
                                ans.put("group", group);
                                ans.put("deviceId", hosts.get(0));
                                ans.put("date", groupId);
                            }
                            a.add(ans);
                            System.out.println("#job_ans: " + ans);
                            //System.out.println(input.get(devID).get("高精度总里程(EE)").size());

                        } catch (Exception e) {
                            e.printStackTrace();
                        }
                        return new Tuple2<>(s.getSecond().get_taskId(), a);//impl.square(1));
                    }
                });
        JavaPairDStream<String, List<Map<String,Object>>> ans = rets.reduceByKey(
                new Function2<List<Map<String,Object>>, List<Map<String,Object>>, List<Map<String,Object>>>() {
                    @Override public List<Map<String,Object>> call(List<Map<String,Object>> i1, List<Map<String,Object>> i2) {
                        i1.addAll(i2);
                        return i1;
                    }
                });
        ans.print();
       //fileOutput
        JavaDStream<Integer> fin = ans.map(new Function<Tuple2<String, List<Map<String,Object>>>, Integer>() {
            @Override
            public Integer call(Tuple2<String, List<Map<String,Object>>> x) throws Exception{
                File file1 = new File("/home/seasons/Desktop/MRO/", x._1() + ".csv");
                if (!file1.exists()){
                    file1.createNewFile();
                }
                FileWriter fw = new FileWriter(file1, true);
                StringBuilder head = new StringBuilder();
                String group = "";
                for (Map<String,Object> it: x._2()){
                    group = (String)it.get("group");
                    if (group.equals("DEVICE&DAY")){
                        head.append("deviceId,date");
                    } else {
                        head.append(group);
                    }
                    for (Map.Entry<String, Object> entry: it.entrySet()){
                        Object key = entry.getKey();
                        if (!key.equals("deviceId") && !key.equals("date") && !key.equals("group"))
                            head.append(",").append(key);
                    }
                    break;
                }
                head.append("\n");
                fw.write(head.toString());
                fw.flush();
                for (Map<String,Object> it: x._2()){
                    StringBuilder str = new StringBuilder();
                    if (group.equals("DEVICE&DAY")){
                        str.append(it.get("deviceId")).append(",").append(it.get("date"));
                    } else {
                        str.append(it.get(group));
                    }
                    for (Map.Entry<String, Object> entry: it.entrySet()){
                        Object key = entry.getKey();
                        if (!key.equals("deviceId") && !key.equals("date") && !key.equals("group"))
                            str.append(",").append(entry.getValue());
                    }
                    str.append("\n");
                    fw.write(str.toString());
                    fw.flush();
                }
                fw.close();
                return 1;
            }
        });
        fin.print();

        jssc.start();
        jssc.awaitTermination();
    }
}
